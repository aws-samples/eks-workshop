<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Autoscaling our Applications and Clusters on Amazon EKS Workshop</title>
    <link>/scaling/</link>
    <description>Recent content in Autoscaling our Applications and Clusters on Amazon EKS Workshop</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Aug 2018 08:30:11 -0700</lastBuildDate>
    
	<atom:link href="/scaling/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Configure Horizontal Pod AutoScaler (HPA)</title>
      <link>/scaling/deploy_hpa/</link>
      <pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate>
      
      <guid>/scaling/deploy_hpa/</guid>
      <description>Deploy the Metrics Server Metrics Server is a cluster-wide aggregator of resource usage data. These metrics will drive the scaling behavior of the deployments. We will deploy the metrics server using Helm configured in a previous module
helm install stable/metrics-server \ --name metrics-server \ --version 2.0.2 \ --namespace metrics  Confirm the Metrics API is available. Return to the terminal in the Cloud9 Environment
kubectl get apiservice v1beta1.metrics.k8s.io -o yaml  If all is well, you should see a status message similar to the one below in the response</description>
    </item>
    
    <item>
      <title>Scale an Application with HPA</title>
      <link>/scaling/test_hpa/</link>
      <pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate>
      
      <guid>/scaling/test_hpa/</guid>
      <description>Deploy a Sample App We will deploy an application and expose as a service on TCP port 80. The application is a custom-built image based on the php-apache image. The index.php page performs calculations to generate CPU load. More information can be found here
kubectl run php-apache --image=k8s.gcr.io/hpa-example --requests=cpu=200m --expose --port=80  Create an HPA resource This HPA scales up when CPU exceeds 50% of the allocated container resource.</description>
    </item>
    
    <item>
      <title>Configure Cluster Autoscaler (CA)</title>
      <link>/scaling/deploy_ca/</link>
      <pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate>
      
      <guid>/scaling/deploy_ca/</guid>
      <description>Cluster Autoscaler for AWS provides integration with Auto Scaling groups. It enables users to choose from four different options of deployment:
 One Auto Scaling group - This is what we will use Multiple Auto Scaling groups Auto-Discovery Master Node setup  Configure the Cluster Autoscaler (CA) We have provided a manifest file to deploy the CA. Copy the commands below into your Cloud9 Terminal.
mkdir ~/environment/cluster-autoscaler cd ~/environment/cluster-autoscaler wget https://eksworkshop.</description>
    </item>
    
    <item>
      <title>Scale a Cluster with CA</title>
      <link>/scaling/test_ca/</link>
      <pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate>
      
      <guid>/scaling/test_ca/</guid>
      <description>Deploy a Sample App We will deploy an sample nginx application as a ReplicaSet of 1 Pod
cat &amp;lt;&amp;lt;EoF&amp;gt; ~/environment/cluster-autoscaler/nginx.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-to-scaleout spec: replicas: 1 template: metadata: labels: service: nginx app: nginx spec: containers: - image: nginx name: nginx-to-scaleout resources: limits: cpu: 500m memory: 512Mi requests: cpu: 500m memory: 512Mi EoF kubectl apply -f ~/environment/cluster-autoscaler/nginx.yaml kubectl get deployment/nginx-to-scaleout  Scale our ReplicaSet OK, let&amp;rsquo;s scale out the replicaset to 10</description>
    </item>
    
    <item>
      <title>Cleanup Scaling</title>
      <link>/scaling/cleanup/</link>
      <pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate>
      
      <guid>/scaling/cleanup/</guid>
      <description>INSTANCE_PROFILE_PREFIX=$(aws cloudformation describe-stacks --stack-name eksctl-eksworkshop-eksctl-nodegroup-0 | jq -r &#39;.Stacks[].Outputs[].ExportName&#39; | sed &#39;s/:.*//&#39;) INSTANCE_PROFILE_NAME=$(aws iam list-instance-profiles | jq -r &#39;.InstanceProfiles[].InstanceProfileName&#39; | grep $INSTANCE_PROFILE_PREFIX) ROLE_NAME=$(aws iam get-instance-profile --instance-profile-name $INSTANCE_PROFILE_NAME | jq -r &#39;.InstanceProfile.Roles[] | .RoleName&#39;) kubectl delete -f ~/environment/cluster-autoscaler/cluster_autoscaler.yml kubectl delete -f ~/environment/cluster-autoscaler/nginx.yaml rm -rf ~/environment/cluster-autoscaler aws iam delete-role-policy --role-name $ROLE_NAME --policy-name ASG-Policy-For-Worker kubectl delete hpa,svc php-apache kubectl delete deployment php-apache load-generator  </description>
    </item>
    
  </channel>
</rss>